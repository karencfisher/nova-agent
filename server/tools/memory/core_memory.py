import json
import os
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS

class CoreMemory:
    # tool description 
    description = "Memory of information about you, the agent, or the human "\
    + "you are chatting with. Set if the memory is contextual, specific to the "\
    + "current topic, or if it applies to all conversations from now on. Information "\
    + "is stored as "\
    + "key/value pairs. "

    # arguments into the tool (generated by the LLM)
    # defines what the agent must generate to input into the tool 
    properties = {
        # arg 1: section of memory to edit
        "section": {
            "type": "string",
            "enum": ["human", "agent"],
            "description": "Must be either 'human' " \
            + "(to save information about the human) or 'agent'" \
            + "(to save information about yourself)",            
        },
        "contextual": {
            "type": "boolean",
            "description": "Whether memory is contextual, specific to a "\
            + "conversation, or general. True if contextual, False if general",
        },
        # arg 2 & 3: memory to save
        "memory_key": {
            "type": "string",
            "description": "Memory key to save in the section",
        },
        "memory_value": {
            "type": "string",
            "description": "Memory value to save in the section"
        }
    }
    
    with open('tools\\memory\\agent_memory.json', 'r', encoding='utf-8') as FILE:
        agent_memory = json.load(FILE)
            
    def memory_save(section, contextual, memory_key, memory_value):
        if contextual and section == 'human':
            print('Saving contextual memory for human')
            ContextMemory().store_memory({
                'key': memory_key,
                'content': memory_value
            })
        else:
            CoreMemory.agent_memory[section][memory_key] = memory_value
            CoreMemory.persist_memory()
        return f'Updated memory'
           
    def persist_memory():
        with open('tools\\memory\\agent_memory.json', 'w', encoding='utf-8') as FILE:
            json.dump(CoreMemory.agent_memory, FILE)
            
            
class MemoryRetrieval:
    description = "Retrieve memories from the agent's memory whenever you chose to use. "\
        + "during conversation."
    
    properties = {
        "query": {
            "type": "string",
            "description": "Query to search for in the memory",
        }
    }   
    
    def memory_retrieve(query):
        # from context memory
        documents = ContextMemory().retrieve_memories(query, 10)
        return documents
            
        
class ContextMemory:
    def __init__(self):
        self.embeddings = HuggingFaceEmbeddings()
        if not os.path.exists('tools\\memory\\messages_index'):
            self.messages_index = None
        else:
            self.messages_index = FAISS.load_local(
                'tools\\memory\\messages_index', 
                self.embeddings, 
                allow_dangerous_deserialization=True
            )
    
    def retrieve_memories(self, query, k):
        if not query:
            return ""
        if not os.path.exists('tools\\memory\\messages_index'):
            return ""
        self.messages_index = FAISS.load_local(
            'tools\\memory\\messages_index',
            self.embeddings,
            allow_dangerous_deserialization=True
        )
        documents =  self.messages_index.similarity_search_with_score(query, k=k)
        messages = [doc[0].page_content for doc in documents if doc[1] < 1.2]
        print(f"Retrieved memories: {messages}")
        return '\n'.join(messages) 
    
    def store_memory(self, memory):
        # messages list of messages to store in vector db
        document = Document(
            page_content=f"{memory['key']}: {memory['content']}"
        )   
        if self.messages_index is None:
            self.messages_index = FAISS.from_documents([document], self.embeddings)
        else:
            self.messages_index.add_documents([document])
        self.messages_index.save_local('tools\\memory\\messages_index')  
    